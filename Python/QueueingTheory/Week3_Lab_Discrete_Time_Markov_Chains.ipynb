{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=\"4\">  MOOC: Understanding queues</font></p>\n",
    "<p><font size=\"4\">  Python simulations</p>\n",
    "<p><font size=\"4\">  Week III: Discrete time Markov chains </p>\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we consider the Markov chain of the weather forecast example of the course. We check convergence of the probability $\\pi(t)$ of the chain at time $t$ to a steady state distribution $\\pi^*$, independently from the initial distribution $\\pi(0)$ of the chain. We solve the load balance equations to get $\\pi^*$.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the Markov chain of the weather forecast example of the course. Recall that its states 1, 2 and 3 represent clear, cloudy and rainy states, and the transition matrix is\n",
    "\n",
    "$$\n",
    "P=\n",
    "\\begin{pmatrix}\n",
    "0.7 & 0.3 & 0\\\\\n",
    "0.3 & 0.5 & 0.2\\\\\n",
    "0.1 & 0.4 & 0.5\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "**1)** Complete below the code of the function that generates trajectories of the Markov chain. The function inputs are the chain initial state $x0$, the transition matrix $P$ and final time index $T$. Its output will be a  trajectory $x$ of the chain observed between instants $0$ and $T$. Draw a trajectory of the evolution of the weather between time 0 and time $T=100$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline              \n",
    "from pylab import *          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P    = array([[.7, .3, 0], [.3, .5, .2], [.1, .4, .5]])\n",
    "\n",
    "def X(x0,P=P,T=100):\n",
    "    # Function X supplies a trajectory of the discrete Markov chain \n",
    "    # with initial state x0 and transition matrix P, till time T\n",
    "    x        = [x0]\n",
    "    for _ in range(T):\n",
    "        #####################\n",
    "        # supply the vector p of probabilities to transit to states\n",
    "        # 1,2,3 from the last calculated state\n",
    "        p = ...\n",
    "        #####################\n",
    "        u = rand()\n",
    "        if u<p[0]:\n",
    "            x.append(1)\n",
    "        elif u<p[0]+p[1]:\n",
    "            x.append(2)\n",
    "        else:\n",
    "            x.append(3)\n",
    "    return array(x)\n",
    "\n",
    "V1 = mean(X(x0=1,T=10**4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x,y,Tmax=0,color='b'):\n",
    "    # step function\n",
    "    # plots a step function representing the number\n",
    "    # of clients in the system at each instant\n",
    "    if Tmax==0:\n",
    "        Tmax = max(x)\n",
    "    x = append(x,[Tmax])  # number of clients\n",
    "    y = append(y,[y[-1]]) # instants of events\n",
    "    for k in range(len(x)-1):\n",
    "        vlines(x[k+1],y[k],y[k+1],color=color)\n",
    "        hlines(y[k],x[k],x[k+1],color=color)\n",
    "        \n",
    "T = 100\n",
    "x = X(x0=1)\n",
    "figure(num=None, figsize=(15, 4))\n",
    "step(range(T),x)\n",
    "axis(ymin=0.5,ymax=3.5)\n",
    "xlabel(\"Time\")\n",
    "title(\"Weather\")\n",
    "yticks([1.0,2.0,3.0], [\"Clear\",\"Cloudy\",\"Rainy\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Run the following code that computes recursively the state probability vectors $\\pi(t)$ at times $t=0,\\ldots,100$. The state probability vectors can be computed recursively : $\\pi(t+1)=\\pi(t) P$. Check that, when changing the initial state $x0$, $\\pi(t)$ still converges rapidly to the same asymptotic vector $\\pi^*$ as $t$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 20\n",
    "\n",
    "def PI(pi0,P=P,T=T):\n",
    "    # Function PI computes the state probability vectors\n",
    "    # of the Markov chain until time T\n",
    "    pi_ = array([pi0])\n",
    "    for i in range(T):\n",
    "        pi_ = vstack((pi_,pi_[-1] @ P))\n",
    "    return pi_\n",
    "\n",
    "def plot_PI(x0):\n",
    "    # subplot(1,3,n+1) of successive states probabilities \n",
    "    # with initial state x0\n",
    "    pi_0       = zeros(3)\n",
    "    pi_0[x0-1] = 1\n",
    "    pi_  = PI(pi_0)\n",
    "    subplot(1,3,x0)\n",
    "    plot(pi_)\n",
    "    xlabel('t');axis(ymin=0,ymax=1)\n",
    "    if x0==1: ylabel(r\"$\\pi(t)$\")\n",
    "    if x0==2: title(\"Evolution of $P(X_t)=1,2,3$.\")\n",
    "\n",
    "rcParams[\"figure.figsize\"] = (10., 4.)\n",
    "for x0 in range(1,4):\n",
    "    plot_PI(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** To compute the steady state distribution $\\pi^*=[\\pi^*_1,\\pi^*_2,\\pi^*_3]$, we must solve the system of load balance equations $\\pi^*=\\pi^* P$ with the normalization condition $\\pi^*_1+\\pi^*_2+\\pi^*_3=1$. The system of equations $\\pi^*=\\pi^* P$ is redundant : the third equation is a straightforward linear combination of the first two ones. Taking into account the normalization condition $\\pi^*_1+\\pi^*_2+\\pi^*_3=1$ and discarding the third redundant equation in $\\pi^*(P-I_3)=0$ yields a full rank system of equations. Complete the code below to solve this system and obtain the steady state ditribution. We will use the [solve](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve.html#scipy.linalg.solve)\n",
    "function from the **scipy.linalg** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import solve\n",
    "####################\n",
    "# complete the code to get the steady state distribution\n",
    "# of the discrete time Markov chain\n",
    "pi_ = solve(... , ...)\n",
    "print(\"steady state distribution: pi* =\",pi_)\n",
    "####################\n",
    "V2,V3 = pi_[0],pi_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answers for the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------\\n\"\n",
    "      +\"RESULTS SUPPLIED FOR LAB 3:\\n\"\n",
    "      +\"---------------------------\")\n",
    "results = (\"V\"+str(k) for k in range(1,4))\n",
    "for x in results:\n",
    "    try:\n",
    "        print(x+\" = {0:.2f}\".format(eval(x)))\n",
    "    except:\n",
    "        print(x+\": variable is undefined\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
